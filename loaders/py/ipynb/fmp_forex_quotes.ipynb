{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T21:11:09.613186Z",
     "iopub.status.busy": "2025-01-05T21:11:09.612772Z",
     "iopub.status.idle": "2025-01-05T21:11:09.711951Z",
     "shell.execute_reply": "2025-01-05T21:11:09.710998Z"
    }
   },
   "outputs": [],
   "source": [
    "%run ../make_clean_names.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T21:11:09.715009Z",
     "iopub.status.busy": "2025-01-05T21:11:09.714709Z",
     "iopub.status.idle": "2025-01-05T21:11:09.785796Z",
     "shell.execute_reply": "2025-01-05T21:11:09.785166Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import logging\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import polars as pl\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "    retries = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504]\n",
    "    )\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries, pool_maxsize=10))\n",
    "    return session\n",
    "\n",
    "# Get API key from environment variables\n",
    "FMP_API_KEY = os.getenv('FMP_API_KEY')\n",
    "if not FMP_API_KEY:\n",
    "    raise ValueError(\"FMP_API_KEY not found in environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Forex Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pairs(file_path: str) -> List[str]:\n",
    "    \"\"\"Load pairs from a text file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            pairs = [line.strip() for line in f if line.strip()]\n",
    "        print(f\"Loaded {len(pairs)} pairs from {file_path}\")\n",
    "        return pairs\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pairs: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "pairs_file = '../fx_pairs.txt'\n",
    "pairs = load_pairs(pairs_file)\n",
    "\n",
    "if pairs:\n",
    "    print(\"pairs:\", pairs)\n",
    "else:\n",
    "    print(\"No pairs loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Data from FMP into Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T21:11:09.788308Z",
     "iopub.status.busy": "2025-01-05T21:11:09.787920Z",
     "iopub.status.idle": "2025-01-05T21:11:10.891386Z",
     "shell.execute_reply": "2025-01-05T21:11:10.890451Z"
    }
   },
   "outputs": [],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "def fetch_forex_data(pair: str, api_key: str, session: requests.Session) -> Dict:\n",
    "    \"\"\"Fetch historical forex data for a single pair with pair identifier\"\"\"\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical-chart/1day/{pair}\"\n",
    "    params = {\n",
    "        \"from\": start_date,\n",
    "        \"to\": end_date,\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "        response = session.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        # Add pair identifier to each record\n",
    "        return [{\"pair\": pair, **record} for record in data] if data else None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching {pair}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def fetch_all_forex_data(pairs: List[str], api_key: str) -> List[Dict]:\n",
    "    \"\"\"Fetch and combine forex data for multiple pairs\"\"\"\n",
    "    session = create_session()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [\n",
    "            executor.submit(fetch_forex_data, pair, api_key, session)\n",
    "            for pair in pairs\n",
    "        ]\n",
    "        results = [\n",
    "            f.result() for f in concurrent.futures.as_completed(futures)\n",
    "        ]\n",
    "    \n",
    "    # Flatten results list and remove None values\n",
    "    all_data = []\n",
    "    for result in results:\n",
    "        if result:\n",
    "            all_data.extend(result)\n",
    "    return all_data\n",
    "\n",
    "# Execute fetching\n",
    "fx_data = fetch_all_forex_data(pairs, FMP_API_KEY)\n",
    "\n",
    "# Convert to Polars DataFrame if data exists\n",
    "if fx_data:\n",
    "    df = pl.DataFrame(fx_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T21:11:10.893515Z",
     "iopub.status.busy": "2025-01-05T21:11:10.893362Z",
     "iopub.status.idle": "2025-01-05T21:11:10.897662Z",
     "shell.execute_reply": "2025-01-05T21:11:10.896991Z"
    }
   },
   "outputs": [],
   "source": [
    "df = make_clean_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Write Polars to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T21:11:10.899127Z",
     "iopub.status.busy": "2025-01-05T21:11:10.899008Z",
     "iopub.status.idle": "2025-01-05T21:11:10.913058Z",
     "shell.execute_reply": "2025-01-05T21:11:10.912564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = \"../../../data/finance\"\n",
    "\n",
    "# Write the processed DataFrame to a Parquet file\n",
    "df.write_parquet(f'{output_dir}/historical_fx_quotes.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Read Parquet (Validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T21:11:10.914547Z",
     "iopub.status.busy": "2025-01-05T21:11:10.914370Z",
     "iopub.status.idle": "2025-01-05T21:11:10.920915Z",
     "shell.execute_reply": "2025-01-05T21:11:10.920469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validate the output by reading the Parquet file and displaying the first few rows\n",
    "pl.scan_parquet(f'{output_dir}/historical_fx_quotes.parquet').head().collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
